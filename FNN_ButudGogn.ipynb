{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FNN_ButudGogn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPRIv8WMfh4f"
      },
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "X_test = np.load('/content/drive/MyDrive/Skóli/3V/Gervigreind/Lokaverkefni/time_dependant_fylki/x_test_file.npy')\n",
        "y_test = np.load('/content/drive/MyDrive/Skóli/3V/Gervigreind/Lokaverkefni/time_dependant_fylki/y_test_file.npy')\n",
        "X_train = np.load('/content/drive/MyDrive/Skóli/3V/Gervigreind/Lokaverkefni/time_dependant_fylki/x_train_file.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/Skóli/3V/Gervigreind/Lokaverkefni/time_dependant_fylki/y_train_file.npy')\n",
        "X_val = np.load('/content/drive/MyDrive/Skóli/3V/Gervigreind/Lokaverkefni/time_dependant_fylki/x_val_file.npy')\n",
        "y_val = np.load('/content/drive/MyDrive/Skóli/3V/Gervigreind/Lokaverkefni/time_dependant_fylki/y_val_file.npy')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UorcDKbSt9d"
      },
      "source": [
        "def reduced(X):\n",
        "    heildin = np.zeros([X.shape[0], 140])\n",
        "    for i in range(X.shape[0]):\n",
        "        f = X[i]\n",
        "\n",
        "        medal = np.mean(f, axis=0)\n",
        "        stadal = np.std(f, axis=0)\n",
        "        skewid = stats.skew(f, axis=0)\n",
        "        kurtosisinn = stats.kurtosis(f, axis=0)\n",
        "        medianinn = np.median(f, axis=0)\n",
        "        minid = np.min(f, axis=0)\n",
        "        maxid = np.max(f, axis=0)\n",
        "\n",
        "        fylki = np.append(medal, stadal)\n",
        "        fylki = np.append(fylki, skewid)\n",
        "        fylki = np.append(fylki, kurtosisinn)\n",
        "        fylki = np.append(fylki, medianinn)\n",
        "        fylki = np.append(fylki, minid)\n",
        "        fylki = np.append(fylki, maxid)\n",
        "        heildin[i,:] = fylki\n",
        "    return heildin"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIitZ3DCn4Cz"
      },
      "source": [
        "X_train_nytt = reduced(X_train)\n",
        "X_test_nytt = reduced(X_test)\n",
        "X_val_nytt = reduced(X_val)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXpetgw-XELR",
        "outputId": "df2409e0-24ea-4d0e-c271-03e470ec8b76"
      },
      "source": [
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, LabelBinarizer, StandardScaler\n",
        "scaler = StandardScaler(copy=False)\n",
        "scaler.fit_transform(X_train_nytt)\n",
        "scaler.transform(X_val_nytt)\n",
        "scaler.transform(X_test_nytt)\n",
        "\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "model = keras.Sequential([\n",
        "\n",
        "\n",
        "    # 1st dense layer\n",
        "    keras.layers.Dense(128, input_dim=X_train_nytt.shape[1],activation='relu', kernel_regularizer = keras.regularizers.l2(0.0002)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "\n",
        "    # 2nd dense layer\n",
        "    keras.layers.Dense(64, activation='relu', kernel_regularizer = keras.regularizers.l2(0.0002)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "\n",
        "    # 3rd dense layer\n",
        "    keras.layers.Dense(32, activation='relu', kernel_regularizer = keras.regularizers.l2(0.0002)),\n",
        "    keras.layers.Dropout(0.3),\n",
        "\n",
        "    # output layer\n",
        "    keras.layers.Dense(8, activation='softmax')\n",
        "])\n",
        "\n",
        "# compile model\n",
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# train model\n",
        "history = model.fit(X_train_nytt, y_train, validation_data=(X_val_nytt, y_val), batch_size=32, epochs=130)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               18048     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 264       \n",
            "=================================================================\n",
            "Total params: 28,648\n",
            "Trainable params: 28,648\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/130\n",
            "882/882 [==============================] - 6s 3ms/step - loss: 2.2989 - accuracy: 0.1491 - val_loss: 1.9043 - val_accuracy: 0.3654\n",
            "Epoch 2/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.9915 - accuracy: 0.2614 - val_loss: 1.7830 - val_accuracy: 0.4012\n",
            "Epoch 3/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.9014 - accuracy: 0.3148 - val_loss: 1.7104 - val_accuracy: 0.4292\n",
            "Epoch 4/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.8424 - accuracy: 0.3387 - val_loss: 1.6580 - val_accuracy: 0.4498\n",
            "Epoch 5/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.8048 - accuracy: 0.3591 - val_loss: 1.6227 - val_accuracy: 0.4571\n",
            "Epoch 6/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.7618 - accuracy: 0.3808 - val_loss: 1.5995 - val_accuracy: 0.4709\n",
            "Epoch 7/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.7407 - accuracy: 0.3921 - val_loss: 1.5840 - val_accuracy: 0.4766\n",
            "Epoch 8/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.7327 - accuracy: 0.3966 - val_loss: 1.5685 - val_accuracy: 0.4791\n",
            "Epoch 9/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.7049 - accuracy: 0.4045 - val_loss: 1.5530 - val_accuracy: 0.4850\n",
            "Epoch 10/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.6900 - accuracy: 0.4089 - val_loss: 1.5430 - val_accuracy: 0.4814\n",
            "Epoch 11/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.6784 - accuracy: 0.4176 - val_loss: 1.5350 - val_accuracy: 0.4859\n",
            "Epoch 12/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.6580 - accuracy: 0.4240 - val_loss: 1.5289 - val_accuracy: 0.4921\n",
            "Epoch 13/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.6491 - accuracy: 0.4250 - val_loss: 1.5198 - val_accuracy: 0.4932\n",
            "Epoch 14/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.6366 - accuracy: 0.4318 - val_loss: 1.5119 - val_accuracy: 0.4975\n",
            "Epoch 15/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.6226 - accuracy: 0.4404 - val_loss: 1.5092 - val_accuracy: 0.4946\n",
            "Epoch 16/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.6166 - accuracy: 0.4428 - val_loss: 1.5035 - val_accuracy: 0.4946\n",
            "Epoch 17/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5953 - accuracy: 0.4515 - val_loss: 1.5044 - val_accuracy: 0.4960\n",
            "Epoch 18/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.6010 - accuracy: 0.4468 - val_loss: 1.4940 - val_accuracy: 0.5025\n",
            "Epoch 19/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5823 - accuracy: 0.4533 - val_loss: 1.4891 - val_accuracy: 0.5065\n",
            "Epoch 20/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5747 - accuracy: 0.4573 - val_loss: 1.4864 - val_accuracy: 0.5071\n",
            "Epoch 21/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5840 - accuracy: 0.4569 - val_loss: 1.4758 - val_accuracy: 0.5093\n",
            "Epoch 22/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5774 - accuracy: 0.4536 - val_loss: 1.4767 - val_accuracy: 0.5133\n",
            "Epoch 23/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5745 - accuracy: 0.4613 - val_loss: 1.4739 - val_accuracy: 0.5155\n",
            "Epoch 24/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5573 - accuracy: 0.4663 - val_loss: 1.4681 - val_accuracy: 0.5119\n",
            "Epoch 25/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5454 - accuracy: 0.4690 - val_loss: 1.4623 - val_accuracy: 0.5178\n",
            "Epoch 26/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5416 - accuracy: 0.4719 - val_loss: 1.4654 - val_accuracy: 0.5130\n",
            "Epoch 27/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5417 - accuracy: 0.4693 - val_loss: 1.4609 - val_accuracy: 0.5150\n",
            "Epoch 28/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5327 - accuracy: 0.4728 - val_loss: 1.4580 - val_accuracy: 0.5141\n",
            "Epoch 29/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5314 - accuracy: 0.4711 - val_loss: 1.4506 - val_accuracy: 0.5189\n",
            "Epoch 30/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5168 - accuracy: 0.4794 - val_loss: 1.4550 - val_accuracy: 0.5164\n",
            "Epoch 31/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5281 - accuracy: 0.4735 - val_loss: 1.4512 - val_accuracy: 0.5183\n",
            "Epoch 32/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5081 - accuracy: 0.4788 - val_loss: 1.4537 - val_accuracy: 0.5155\n",
            "Epoch 33/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5079 - accuracy: 0.4769 - val_loss: 1.4517 - val_accuracy: 0.5175\n",
            "Epoch 34/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5077 - accuracy: 0.4831 - val_loss: 1.4399 - val_accuracy: 0.5214\n",
            "Epoch 35/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.5006 - accuracy: 0.4842 - val_loss: 1.4430 - val_accuracy: 0.5181\n",
            "Epoch 36/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4905 - accuracy: 0.4817 - val_loss: 1.4448 - val_accuracy: 0.5150\n",
            "Epoch 37/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4943 - accuracy: 0.4837 - val_loss: 1.4406 - val_accuracy: 0.5169\n",
            "Epoch 38/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4805 - accuracy: 0.4928 - val_loss: 1.4399 - val_accuracy: 0.5161\n",
            "Epoch 39/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4767 - accuracy: 0.4939 - val_loss: 1.4406 - val_accuracy: 0.5183\n",
            "Epoch 40/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4700 - accuracy: 0.4992 - val_loss: 1.4392 - val_accuracy: 0.5175\n",
            "Epoch 41/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4748 - accuracy: 0.4937 - val_loss: 1.4388 - val_accuracy: 0.5200\n",
            "Epoch 42/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4708 - accuracy: 0.4961 - val_loss: 1.4389 - val_accuracy: 0.5186\n",
            "Epoch 43/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4744 - accuracy: 0.4930 - val_loss: 1.4382 - val_accuracy: 0.5186\n",
            "Epoch 44/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4557 - accuracy: 0.5017 - val_loss: 1.4324 - val_accuracy: 0.5144\n",
            "Epoch 45/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4613 - accuracy: 0.4968 - val_loss: 1.4483 - val_accuracy: 0.5144\n",
            "Epoch 46/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4494 - accuracy: 0.5019 - val_loss: 1.4396 - val_accuracy: 0.5155\n",
            "Epoch 47/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4536 - accuracy: 0.4994 - val_loss: 1.4300 - val_accuracy: 0.5229\n",
            "Epoch 48/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4471 - accuracy: 0.5038 - val_loss: 1.4310 - val_accuracy: 0.5206\n",
            "Epoch 49/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4519 - accuracy: 0.5012 - val_loss: 1.4319 - val_accuracy: 0.5175\n",
            "Epoch 50/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4426 - accuracy: 0.5082 - val_loss: 1.4288 - val_accuracy: 0.5203\n",
            "Epoch 51/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4413 - accuracy: 0.5019 - val_loss: 1.4335 - val_accuracy: 0.5200\n",
            "Epoch 52/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4294 - accuracy: 0.5121 - val_loss: 1.4328 - val_accuracy: 0.5186\n",
            "Epoch 53/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4401 - accuracy: 0.5098 - val_loss: 1.4375 - val_accuracy: 0.5152\n",
            "Epoch 54/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4283 - accuracy: 0.5112 - val_loss: 1.4338 - val_accuracy: 0.5172\n",
            "Epoch 55/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4257 - accuracy: 0.5109 - val_loss: 1.4319 - val_accuracy: 0.5164\n",
            "Epoch 56/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4169 - accuracy: 0.5167 - val_loss: 1.4303 - val_accuracy: 0.5164\n",
            "Epoch 57/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4301 - accuracy: 0.5149 - val_loss: 1.4358 - val_accuracy: 0.5152\n",
            "Epoch 58/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4025 - accuracy: 0.5247 - val_loss: 1.4280 - val_accuracy: 0.5166\n",
            "Epoch 59/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4135 - accuracy: 0.5176 - val_loss: 1.4357 - val_accuracy: 0.5079\n",
            "Epoch 60/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4026 - accuracy: 0.5192 - val_loss: 1.4335 - val_accuracy: 0.5147\n",
            "Epoch 61/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4059 - accuracy: 0.5202 - val_loss: 1.4307 - val_accuracy: 0.5161\n",
            "Epoch 62/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4128 - accuracy: 0.5161 - val_loss: 1.4363 - val_accuracy: 0.5141\n",
            "Epoch 63/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3944 - accuracy: 0.5262 - val_loss: 1.4333 - val_accuracy: 0.5144\n",
            "Epoch 64/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4042 - accuracy: 0.5216 - val_loss: 1.4344 - val_accuracy: 0.5169\n",
            "Epoch 65/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3979 - accuracy: 0.5263 - val_loss: 1.4358 - val_accuracy: 0.5169\n",
            "Epoch 66/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3913 - accuracy: 0.5239 - val_loss: 1.4307 - val_accuracy: 0.5192\n",
            "Epoch 67/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3941 - accuracy: 0.5263 - val_loss: 1.4241 - val_accuracy: 0.5209\n",
            "Epoch 68/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.4023 - accuracy: 0.5176 - val_loss: 1.4272 - val_accuracy: 0.5220\n",
            "Epoch 69/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3834 - accuracy: 0.5302 - val_loss: 1.4288 - val_accuracy: 0.5164\n",
            "Epoch 70/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3792 - accuracy: 0.5270 - val_loss: 1.4314 - val_accuracy: 0.5189\n",
            "Epoch 71/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3740 - accuracy: 0.5330 - val_loss: 1.4272 - val_accuracy: 0.5164\n",
            "Epoch 72/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3824 - accuracy: 0.5316 - val_loss: 1.4317 - val_accuracy: 0.5119\n",
            "Epoch 73/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3690 - accuracy: 0.5340 - val_loss: 1.4346 - val_accuracy: 0.5144\n",
            "Epoch 74/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3709 - accuracy: 0.5347 - val_loss: 1.4367 - val_accuracy: 0.5113\n",
            "Epoch 75/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3698 - accuracy: 0.5340 - val_loss: 1.4335 - val_accuracy: 0.5161\n",
            "Epoch 76/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3659 - accuracy: 0.5335 - val_loss: 1.4319 - val_accuracy: 0.5195\n",
            "Epoch 77/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3796 - accuracy: 0.5258 - val_loss: 1.4309 - val_accuracy: 0.5155\n",
            "Epoch 78/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3643 - accuracy: 0.5384 - val_loss: 1.4368 - val_accuracy: 0.5124\n",
            "Epoch 79/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3685 - accuracy: 0.5370 - val_loss: 1.4395 - val_accuracy: 0.5141\n",
            "Epoch 80/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3711 - accuracy: 0.5318 - val_loss: 1.4362 - val_accuracy: 0.5121\n",
            "Epoch 81/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3637 - accuracy: 0.5352 - val_loss: 1.4318 - val_accuracy: 0.5124\n",
            "Epoch 82/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3560 - accuracy: 0.5429 - val_loss: 1.4405 - val_accuracy: 0.5099\n",
            "Epoch 83/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3644 - accuracy: 0.5417 - val_loss: 1.4281 - val_accuracy: 0.5147\n",
            "Epoch 84/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3567 - accuracy: 0.5408 - val_loss: 1.4291 - val_accuracy: 0.5119\n",
            "Epoch 85/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3485 - accuracy: 0.5419 - val_loss: 1.4297 - val_accuracy: 0.5138\n",
            "Epoch 86/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3481 - accuracy: 0.5436 - val_loss: 1.4328 - val_accuracy: 0.5104\n",
            "Epoch 87/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3419 - accuracy: 0.5444 - val_loss: 1.4380 - val_accuracy: 0.5113\n",
            "Epoch 88/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3461 - accuracy: 0.5453 - val_loss: 1.4380 - val_accuracy: 0.5079\n",
            "Epoch 89/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3507 - accuracy: 0.5384 - val_loss: 1.4330 - val_accuracy: 0.5141\n",
            "Epoch 90/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3429 - accuracy: 0.5441 - val_loss: 1.4371 - val_accuracy: 0.5110\n",
            "Epoch 91/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3381 - accuracy: 0.5449 - val_loss: 1.4400 - val_accuracy: 0.5124\n",
            "Epoch 92/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3415 - accuracy: 0.5470 - val_loss: 1.4412 - val_accuracy: 0.5090\n",
            "Epoch 93/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3425 - accuracy: 0.5448 - val_loss: 1.4365 - val_accuracy: 0.5119\n",
            "Epoch 94/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3369 - accuracy: 0.5480 - val_loss: 1.4372 - val_accuracy: 0.5073\n",
            "Epoch 95/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3351 - accuracy: 0.5506 - val_loss: 1.4352 - val_accuracy: 0.5073\n",
            "Epoch 96/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3389 - accuracy: 0.5490 - val_loss: 1.4357 - val_accuracy: 0.5107\n",
            "Epoch 97/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3272 - accuracy: 0.5515 - val_loss: 1.4379 - val_accuracy: 0.5076\n",
            "Epoch 98/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3333 - accuracy: 0.5516 - val_loss: 1.4343 - val_accuracy: 0.5085\n",
            "Epoch 99/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3259 - accuracy: 0.5510 - val_loss: 1.4354 - val_accuracy: 0.5062\n",
            "Epoch 100/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3146 - accuracy: 0.5527 - val_loss: 1.4398 - val_accuracy: 0.5014\n",
            "Epoch 101/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3283 - accuracy: 0.5519 - val_loss: 1.4391 - val_accuracy: 0.5025\n",
            "Epoch 102/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3211 - accuracy: 0.5528 - val_loss: 1.4400 - val_accuracy: 0.5031\n",
            "Epoch 103/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3094 - accuracy: 0.5596 - val_loss: 1.4363 - val_accuracy: 0.5107\n",
            "Epoch 104/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3115 - accuracy: 0.5591 - val_loss: 1.4385 - val_accuracy: 0.5087\n",
            "Epoch 105/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3329 - accuracy: 0.5517 - val_loss: 1.4366 - val_accuracy: 0.5087\n",
            "Epoch 106/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3261 - accuracy: 0.5539 - val_loss: 1.4376 - val_accuracy: 0.5090\n",
            "Epoch 107/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3259 - accuracy: 0.5527 - val_loss: 1.4355 - val_accuracy: 0.5051\n",
            "Epoch 108/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3114 - accuracy: 0.5593 - val_loss: 1.4413 - val_accuracy: 0.5073\n",
            "Epoch 109/130\n",
            "882/882 [==============================] - 2s 3ms/step - loss: 1.3125 - accuracy: 0.5609 - val_loss: 1.4399 - val_accuracy: 0.5037\n",
            "Epoch 110/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3124 - accuracy: 0.5563 - val_loss: 1.4400 - val_accuracy: 0.5127\n",
            "Epoch 111/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3109 - accuracy: 0.5589 - val_loss: 1.4375 - val_accuracy: 0.5068\n",
            "Epoch 112/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3036 - accuracy: 0.5586 - val_loss: 1.4433 - val_accuracy: 0.5037\n",
            "Epoch 113/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3025 - accuracy: 0.5649 - val_loss: 1.4431 - val_accuracy: 0.5085\n",
            "Epoch 114/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3070 - accuracy: 0.5639 - val_loss: 1.4416 - val_accuracy: 0.5059\n",
            "Epoch 115/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2936 - accuracy: 0.5666 - val_loss: 1.4383 - val_accuracy: 0.5037\n",
            "Epoch 116/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2942 - accuracy: 0.5629 - val_loss: 1.4421 - val_accuracy: 0.5000\n",
            "Epoch 117/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2952 - accuracy: 0.5691 - val_loss: 1.4415 - val_accuracy: 0.5048\n",
            "Epoch 118/130\n",
            "882/882 [==============================] - 2s 3ms/step - loss: 1.3008 - accuracy: 0.5660 - val_loss: 1.4439 - val_accuracy: 0.5025\n",
            "Epoch 119/130\n",
            "882/882 [==============================] - 2s 3ms/step - loss: 1.2873 - accuracy: 0.5676 - val_loss: 1.4524 - val_accuracy: 0.4960\n",
            "Epoch 120/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2996 - accuracy: 0.5612 - val_loss: 1.4485 - val_accuracy: 0.5011\n",
            "Epoch 121/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2939 - accuracy: 0.5659 - val_loss: 1.4416 - val_accuracy: 0.5056\n",
            "Epoch 122/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2902 - accuracy: 0.5635 - val_loss: 1.4442 - val_accuracy: 0.5045\n",
            "Epoch 123/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2759 - accuracy: 0.5716 - val_loss: 1.4515 - val_accuracy: 0.4986\n",
            "Epoch 124/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2927 - accuracy: 0.5665 - val_loss: 1.4528 - val_accuracy: 0.5040\n",
            "Epoch 125/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2900 - accuracy: 0.5637 - val_loss: 1.4504 - val_accuracy: 0.4980\n",
            "Epoch 126/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.3001 - accuracy: 0.5615 - val_loss: 1.4536 - val_accuracy: 0.4994\n",
            "Epoch 127/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2905 - accuracy: 0.5698 - val_loss: 1.4369 - val_accuracy: 0.5051\n",
            "Epoch 128/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2880 - accuracy: 0.5703 - val_loss: 1.4402 - val_accuracy: 0.5042\n",
            "Epoch 129/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2829 - accuracy: 0.5678 - val_loss: 1.4439 - val_accuracy: 0.5000\n",
            "Epoch 130/130\n",
            "882/882 [==============================] - 2s 2ms/step - loss: 1.2873 - accuracy: 0.5725 - val_loss: 1.4493 - val_accuracy: 0.4992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akv9LWLfh6sr",
        "outputId": "3748a9ed-7084-46ea-9f0c-9c89a52a6ca4"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(X_test_nytt, y_test, verbose=0)\n",
        "print('Test accuracy:', test_acc)\n",
        "print('Test loss:', test_loss)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.36672279238700867\n",
            "Test loss: 1.7669527530670166\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}